import re

import lxml.html as lh
import requests
from cachetools import cached, TTLCache
from googletrans import Translator
from bs4 import BeautifulSoup
import pandas as pd

from webhook.helpers.date_helpers import to_date

translator = Translator()

maps = {
    "Diamond Princess": "T√†u Diamon Princess",
    "Italy": "N∆∞·ªõc √ù",
    "Thailand": "Th√°i Lan",
    "Hong Kong": "H·ªìng K√¥ng",
    "China": "Trung Qu·ªëc",
    "S. Korea": "H√†n Qu·ªëc",
    "Iran": "Iran",
    "France": "Ph√°p",
    "Germany": "ƒê·ª©c",
    "Spain": "T√¢y Ban Nha",
    "Japan": "Nh·∫≠t B·∫£n",
    "USA": "Hoa K·ª≥",
    "Switzerland": "Th·ª•y Sƒ©",
    "UK": "Anh",
    "Netherlands": "H√† Lan",
    "Belgium": "B·ªâ",
    "Sweden": "Th·ª•y ƒêi·ªÉn",
    "Norway": "Na Uy",
    "Singapore": "Singapore",
    "Austria": "√Åo",
    "Malaysia": "Malaysia",
    "Bahrain": "Bahrain",
    "Australia": "Ch√¢u √öc",
    "Greece": "Hy l·∫°p",
    "Kuwait": "Kuwait",
    "Canada": "Canada",
    "Iraq": "Iraq",
    "Iceland": "N∆∞·ªõc Iceland",
    "Egypt": "Ai C·∫≠p",
    "Taiwan": "ƒê√†i Loan",
    "UAE": "UAE",
    "India": "·∫§n ƒê·ªô",
    "Lebanon": "Lebanon",
    "Denmark": "ƒêan m·∫°ch",
    "San Marino": "San Marino",
    "Czechia": "C·ªông h√≤a S√©c",
    "Israel": "Israel",
    "Portugal": "B·ªì ƒê√†o Nha",
    "Finland": "Ph·∫ßn Lan",
    "Vietnam": "Vi·ªát Nam V√¥ ƒê·ªãch",
    "Algeria": "Algeria",
    "Brazil": "Brazil",
    "Ireland": "Ireland",
    "Palestine": "Palestine",
    "Oman": "Oman",
    "Russia": "Nga",
    "Ecuador": "Ecuador",
    "Georgia": "Georgia",
    "Romania": "romania",
    "Croatia": "Croatia",
    "Qatar": "Qatar",
    "Slovenia": "Slovenia",
    "Saudi Arabia": "·∫¢ R·∫≠p X√™-√∫t",
    "Macao": "Macao",
    "Estonia": "Estonia",
    "Argentina": "Argentina",
    "Azerbaijan": "Azerbaijan",
    "Mexico": "Mexico",
    "Chile": "Chile",
    "Philippines": "Philippines",
    "Belarus": "Belarus",
    "Indonesia": "Indonesia",
    "Pakistan": "Pakistan",
    "Peru": "Peru",
    "Poland": "Ba Lan",
    "New Zealand": "New Zealand",
    "Costa Rica": "Costa Rica",
    "French Guiana": "Guiana thu·ªôc Ph√°p",
    "Hungary": "Hungary",
    "Afghanistan": "Afghanistan",
    "Senegal": "Senegal",
    "Bulgaria": "Bulgaria",
    "Luxembourg": "Luxembourg",
    "North Macedonia": "B·∫Øc Macedonia",
    "Bosnia and Herzegovina": "Bosnia v√† Herzegovina",
    "Malta": "Malta",
    "Slovakia": "Slovakia",
    "South Africa": "Nam Phi",
    "Cambodia": "Campuchia",
    "Dominican Republic": "C·ªông ho√† Dominicana",
    "Morocco": "Morocco",
    "Cameroon": "Cameroon",
    "Faeroe Islands": "Qu·∫ßn ƒë·∫£o Faroe",
    "Maldives": "Maldives",
    "Andorra": "Andorra",
    "Armenia": "Armenia",
    "Jordan": "Jordan",
    "Latvia": "Latvia",
    "Lithuania": "n∆∞·ªõc Lithuania",
    "Monaco": "Monaco",
    "Nepal": "Nepal",
    "Nigeria": "Nigeria",
    "Sri Lanka": "Sri Lanka",
    "Tunisia": "Tunisia",
    "Ukraine": "Ukraina",
    "Bhutan": "Bhutan",
    "Colombia": "Colombia",
    "Gibraltar": "Gibraltar",
    "Vatican City": "To√† th√°nh Vatican",
    "Liechtenstein": "Liechtenstein",
    "Moldova": "Moldavia",
    "Paraguay": "Paraguay",
    "Serbia": "Serbia",
    "Togo": "Togo",
    "Total:": "To√†n b·ªô:"
}

url = 'https://www.worldometers.info/coronavirus/#countries'

@cached(cache=TTLCache(maxsize=10240, ttl=300))
def crawler():
    # Create a handle, page, to handle the contents of the website
    page = requests.get(url)
    # Store the contents of the website under doc
    doc = lh.fromstring(page.content)
    soup = BeautifulSoup(page.content, 'html.parser')

    table = soup.find('table', attrs={'id': 'main_table_countries_today'})
    # Convert to dataframe
    df = pd.read_html(str(table))[0]
    df = df.fillna(0)
    final_df = df.sort_values(by=['TotalCases'], ascending=False)
    final_df.set_index('Country,Other', inplace=True)
    # Parse the last update time
    last_updated = re.findall(r'Last updated:.+? GMT', doc.text_content())[0]
    last_updated = last_updated.strip('Last updated:')
    last_updated = to_date(last_updated)

    return final_df, last_updated


def convert_name(name):
    return maps.get(name, name)

def generate_one_message(row):
    new = row['NewCases']
    total = row['TotalCases']
    death = row['TotalDeaths']
    new_death = row['NewDeaths']
    recover = row['TotalRecovered']
    name = convert_name(row.name)
    death_ratio = round(death / total * 100, 2)
    recover_ratio = round(recover / total * 100, 2)
    return "{}: üò∑ {} [{}], üíÄ {} [{} {}%], üíä {} [{}%]\n".format(name, int(total), new, int(death), new_death, death_ratio,
                                                                  int(recover), recover_ratio)


def get_data(top_k):
    col, last_updated = crawler()
    total = len(col) - 2
    if top_k == -1:
        top_k = total
    msg = "TOP {}/{} N∆†I C√ì D·ªäCH NGUY HI·ªÇM NH·∫§T.\n\n".format(top_k, total)
    for i in range(top_k):
        msg += generate_one_message(col.iloc[i + 1])
    msg += "=================:\n"
    msg += generate_one_message(col.loc['Vietnam'])
    msg += "=================:\n"
    msg += generate_one_message(col.loc['Total:'])
    msg += "\nC·∫≠p nh·∫≠t m·ªõi nh·∫•t v√†o {}".format(last_updated)
    msg += "\n\nNgu·ªìn tham kh·∫£o: {}".format(url)

    return msg


def handle_data(intent, top_k):
    intent_map = {
        'ask_death': 'deaths',
        'ask_resolve': 'recovered',
        'ask_confirm': 'confirmed',
        'ask_all': 'all',
        'fallback': 'fallback'
    }
    if intent_map[intent] in ["deaths", "recovered", "confirmed", 'all']:
        return get_data(top_k)
    # When fallback
    return "Chatbot ch∆∞a x·ª≠ l√Ω ƒë∆∞·ª£c n·ªôi dung b·∫°n n√≥i."
    # try:
    #     intent_map = {
    #         'ask_death': 'deaths',
    #         'ask_resolve': 'recovered',
    #         'ask_confirm': 'confirmed',
    #         'ask_all': 'all',
    #         'fallback': 'fallback'
    #     }
    #     if intent_map[intent] in ["deaths", "recovered", "confirmed", 'all']:
    #         return get_data(top_k)
    #     # When fallback
    #     return "Chatbot ch∆∞a x·ª≠ l√Ω ƒë∆∞·ª£c n·ªôi dung b·∫°n n√≥i."
    # except:
    #     return "ƒê√£ c√≥ l·ªói x·∫£y ra trong khi c·∫≠p nh·∫≠t d·ªØ li·ªáu. B·∫°n vui l√≤ng th·ª≠ l·∫°i sau"


print(handle_data('ask_all', 30))

